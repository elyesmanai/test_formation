{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a66d2b30-beaf-47ee-8aab-b5a96987b7a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "from collections.abc import MutableMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ca0cb65-d61d-401e-ae4c-802bbc188f37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform the raw nested JSON file into a single level Dataframe compatible dict\n",
    "\n",
    "def flatten_dict(d: MutableMapping, sep: str= '.') -> MutableMapping:\n",
    "    [flat_dict] = pd.json_normalize(d, sep=sep).to_dict(orient='records')\n",
    "    return flat_dict\n",
    "\n",
    "\n",
    "def fully_flatten(d):  \n",
    "    flattened = flatten_dict(d)\n",
    "\n",
    "  ## DEAL WITH METRICS\n",
    "    for version in ['2','30','31']:\n",
    "        try:\n",
    "            flattened[f\"cve.metrics.cvssMetricV{version}\"] = flatten_dict(flattened[f\"cve.metrics.cvssMetricV{version}\"][0])\n",
    "            flattened[f\"cve.metrics.cvssMetricV{version}\"] = True\n",
    "        except:\n",
    "            flattened[f\"cve.metrics.cvssMetricV{version}\"] = np.nan\n",
    "\n",
    "    ## DEAL WITH WEAKNESSES\n",
    "    ## Note: when only one weakness, it's denoted with cve.weakness but if many it's denoted with cve.weaknesses\n",
    "    if \"cve.weakness\" in flattened.keys():\n",
    "        primary_source = np.nan\n",
    "        primary_description = flattened['cve.weaknesses.description'][0]['value']\n",
    "        del flattened['cve.weaknesses.description']\n",
    "        flattened.update({\n",
    "              \"cve.weaknesses.primary.source\":        primary_source,\n",
    "              \"cve.weaknesses.primary.description\":   primary_description,\n",
    "              \"cve.weaknesses.secondary.source\":      np.nan,\n",
    "              \"cve.weaknesses.secondary.description\": np.nan,\n",
    "        })\n",
    "    elif \"cve.weakness\" in flattened.keys():\n",
    "        try:\n",
    "            flattened.update({\n",
    "              \"cve.weaknesses.primary.source\":        flattened['cve.weaknesses'][0]['source'],\n",
    "              \"cve.weaknesses.primary.description\":   flattened['cve.weaknesses'][0]['description'],\n",
    "              \"cve.weaknesses.secondary.source\":      flattened['cve.weaknesses'][1]['source'],\n",
    "              \"cve.weaknesses.secondary.description\": flattened['cve.weaknesses'][1]['description'],\n",
    "            })\n",
    "        except:\n",
    "            flattened.update({\n",
    "              \"cve.weaknesses.primary.source\":        flattened['cve.weaknesses'][0]['source'],\n",
    "              \"cve.weaknesses.primary.description\":   flattened['cve.weaknesses'][0]['description'],\n",
    "              \"cve.weaknesses.secondary.source\":      np.nan,\n",
    "              \"cve.weaknesses.secondary.description\": np.nan\n",
    "            })\n",
    "        finally:\n",
    "            del flattened['cve.weaknesses']\n",
    "\n",
    "    else:\n",
    "        flattened.update({\n",
    "              \"cve.weaknesses.primary.source\":        np.nan,\n",
    "              \"cve.weaknesses.primary.description\":   np.nan,\n",
    "              \"cve.weaknesses.secondary.source\":      np.nan,\n",
    "              \"cve.weaknesses.secondary.description\": np.nan\n",
    "          })\n",
    "\n",
    "    ## DEAL WITH DESCRIPTIONS\n",
    "    flattened.update({\"cve.descriptions.lang.en\": flattened['cve.descriptions'][0]['value']})\n",
    "\n",
    "    try:\n",
    "        value = flattened['cve.descriptions'][1]['value']\n",
    "    except:\n",
    "        value = np.nan\n",
    "    finally:\n",
    "        flattened.update({\"cve.descriptions.lang.es\": value})\n",
    "\n",
    "    del flattened['cve.descriptions']\n",
    "\n",
    "    ## FLATTEN AGAIN TO DEAL WITH NEW NESTED DICTS\n",
    "    flattened = flatten_dict(flattened)\n",
    "\n",
    "    ## DEAL WITH REFERENCES\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            url = flattened['cve.references'][i]['url']\n",
    "            source = flattened['cve.references'][i]['source']\n",
    "        except:\n",
    "            url = np.nan\n",
    "            source = np.nan\n",
    "        finally:\n",
    "            flattened.update({\n",
    "              f\"cve.references.{i}.url\": url,\n",
    "              f\"cve.references.{i}.source\": source\n",
    "            })\n",
    "\n",
    "    del flattened['cve.references']\n",
    "\n",
    "    ## DEAL WITH CONFIGURATIONS\n",
    "    try:\n",
    "        flattened.update({\n",
    "            \"cve.configurations.nodes.operator\": flattened['cve.configurations'][0][\"nodes\"][0]['operator'],\n",
    "            \"cve.configurations.nodes.negate\": flattened['cve.configurations'][0][\"nodes\"][0]['negate'],\n",
    "            \"cve.configurations.nodes.cpeMatch.vulnerable\": flattened['cve.configurations'][0][\"nodes\"][0]['cpeMatch'][0]['vulnerable'],\n",
    "            \"cve.configurations.nodes.cpeMatch.criteria\": flattened['cve.configurations'][0][\"nodes\"][0]['cpeMatch'][0]['criteria'],\n",
    "            \"cve.configurations.nodes.cpeMatch.matchCriteriaId\": flattened['cve.configurations'][0][\"nodes\"][0]['cpeMatch'][0]['matchCriteriaId']\n",
    "        })\n",
    "        del flattened['cve.configurations']\n",
    "    except:\n",
    "        flattened.update({\n",
    "            \"cve.configurations.nodes.operator\": np.nan,\n",
    "            \"cve.configurations.nodes.negate\": np.nan,\n",
    "            \"cve.configurations.nodes.cpeMatch.vulnerable\": np.nan,\n",
    "            \"cve.configurations.nodes.cpeMatch.criteria\": np.nan,\n",
    "            \"cve.configurations.nodes.cpeMatch.matchCriteriaId\": np.nan\n",
    "        })\n",
    "\n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4fc208-4764-46d3-8f4d-3e8d6f418baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap all the data from NVD and store them in a text file. \n",
    "# LAST SCRAP DATE: 19-03-2023\n",
    "\n",
    "for i in range(106):\n",
    "    startIndex = (i * 2000)\n",
    "    resultsPerPage = 2000\n",
    "    API_KEY = \"0a418269-2f9e-400f-b24a-2693b70d9ce3\"\n",
    "    time.sleep(1)\n",
    "    response = requests.get(f\"https://services.nvd.nist.gov/rest/json/cves/2.0/?resultsPerPage={resultsPerPage}&startIndex={startIndex}\", headers={'apiKey': API_KEY})\n",
    "    content = json.loads(response.content)['vulnerabilities']\n",
    "    # Append data to file\n",
    "    with open(\"Data/api_cves.txt\", \"a\") as f:\n",
    "        for item in content:\n",
    "            f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d84cb5-f8d2-445d-8ca6-08097dbc6314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from file\n",
    "with open(\"api_cves.txt\", \"r\") as f:\n",
    "    loaded_data = []\n",
    "    [loaded_data.append(json.loads(line)) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74a8995-c192-4966-9f78-0de0cddace05",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = []\n",
    "\n",
    "for i,cve in tqdm(enumerate(loaded_data)):\n",
    "    if cve['cve']['vulnStatus'] not in ['Rejected','Deferred']:\n",
    "        flattened = fully_flatten(cve)\n",
    "        processed.append(flattened)\n",
    "\n",
    "df = pd.DataFrame.from_dict(processed)\n",
    "print(\"df.shape: \", df.shape)\n",
    "\n",
    "print('total CVEs scrapped: ', len(loaded_data))\n",
    "print('Rejected CVEs: ', len(loaded_data) - df.shape[0])\n",
    "print('Useable CVEs: ', df.shape[0])\n",
    "\n",
    "# Just in case\n",
    "df.fillna(value=np.nan,inplace=True)\n",
    "df.replace('NaN',np.nan, inplace=True)\n",
    "\n",
    "# Type conversion error because of mixed types\n",
    "df['cve.configurations.nodes.negate'] = df['cve.configurations.nodes.negate'].astype('string') \n",
    "df['cve.configurations.nodes.cpeMatch.vulnerable'] = df['cve.configurations.nodes.cpeMatch.vulnerable'].astype('string') \n",
    "\n",
    "for i,row in tqdm(df.iterrows()):\n",
    "    for metric in ['cvssMetricV2', 'cvssMetricV30', 'cvssMetricV31']:\n",
    "        column = f'cve.metrics.{metric}'\n",
    "        if row.filter(regex=column+'.').isna().sum() == 0:\n",
    "            df.at[i, column] = True\n",
    "        elif row.filter(regex=column+'.').isna().sum() == 16:\n",
    "            df.at[i, column] = False\n",
    "        else:\n",
    "            df.at[i, column] = \"?\"\n",
    "\n",
    "df.to_csv('data/raw_cves.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f53a8a9-5cd7-4841-91ab-1a9fe100c93b",
   "metadata": {},
   "source": [
    "## Al9a kifeh t'int√©gri hal code lfou9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e0a758-f168-446f-be6f-5d011c5d0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vulnerability status check\n",
    "df['cve.vulnStatus'].value_counts()\n",
    "\n",
    "for metric in ['cvssMetricV2', 'cvssMetricV30', 'cvssMetricV31']:\n",
    "    print(metric,': ')\n",
    "    print(df[metric].value_counts())\n",
    "\n",
    "df['version'] = df['cve.published']\n",
    "df ['tayech'] = df[\"cve.metrics.cvssMetricV2\"].replace(\"?\", True).astype(bool)\n",
    "\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    binary_vector = row[[\"cve.metrics.cvssMetricV30\",\"cve.metrics.cvssMetricV31\",\"tayech\"]].values\n",
    "    if (binary_vector[0] == False) and (binary_vector[1] == False) and (binary_vector[2] == True):\n",
    "        df.at[i,\"version\"] = \"V2\"\n",
    "    elif (binary_vector[0] == True) and (binary_vector[1] == False) and (binary_vector[2] == False):\n",
    "        df.at[i,\"version\"] = \"V3.0\"\n",
    "    elif (binary_vector[0] == False) and (binary_vector[1] == True) and (binary_vector[2] == False):\n",
    "        df.at[i,\"version\"] = \"V3.1\"\n",
    "    elif (binary_vector[0] == True) and (binary_vector[1] == True) and (binary_vector[2] == False):\n",
    "        df.at[i,\"version\"] = \"V3.X\"\n",
    "    elif (binary_vector[0] == False) and (binary_vector[1] == True) and (binary_vector[2] == True):\n",
    "        df.at[i,\"version\"] = 'V2 & V3.1'\n",
    "    elif (binary_vector[0] == True) and (binary_vector[1] == False) and (binary_vector[2] == True):\n",
    "        df.at[i,\"version\"] = 'V2 & V3.0'\n",
    "    elif (binary_vector[0] == True) and (binary_vector[1] == True) and (binary_vector[2] == True):\n",
    "        df.at[i,\"version\"] = 'all'\n",
    "    else:\n",
    "        df.at[i,\"version\"] = 'other'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
